{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "from unidecode import unidecode\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1. Tareas de Adquisición de Data**\n",
    "---\n",
    "Con ayuda de la api PubTator 3 https://www.ncbi.nlm.nih.gov/research/pubtator3/ se puede extraer una colección de textos en formato tipo Json. La colección de textos hacen parte de los resumenes (abstracts) de interés. En esta etapa se incluye la extracción de ciertas características de los textos. En nuestro caso, nos interesaba extraer segmentos de palabras que correspondieran a las categorías: Disease, Specie y gracias a una lista (bolsa de palabras) elaborada previamente se pudo extraer los términos relacionados a (lípidos) para cada texto (abstract) de interés.\n",
    "\n",
    "De los archivos tipo .json se puede extraer la siguiente información relevante\n",
    "\n",
    "*   id\n",
    "*   abstract\n",
    "*   disease\n",
    "*   specie\n",
    "*   peptide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy.cli.download(\"en_core_web_sm\")\n",
    "\n",
    "nlp = spacy.load(\n",
    "        \"en_core_web_sm\",\n",
    "        exclude=[\n",
    "            \"tok2vec\",\n",
    "            \"morphologizer\",\n",
    "            \"parser\",\n",
    "            \"senter\",\n",
    "            \"attribute_ruler\",\n",
    "            \"lemmatizer\",\n",
    "            \"ner\"\n",
    "            ]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "files = glob.glob(\"*.json\")\n",
    "print (files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def json_to_list(numb_articles):\n",
    "    #Function to join all json files\n",
    "    output_data = []\n",
    "    #number_articles = np.arange(100, numb_articles+100, 100).tolist()\n",
    "    #for i in number_articles:\n",
    "    for i in files:\n",
    "        with open(i) as f:\n",
    "            for line in f:\n",
    "                output_data.append(json.loads(line))\n",
    "    return output_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_jsons_to_df(input_data):\n",
    "    #Function to extract Data from all json files\n",
    "    df_article = pd.DataFrame()\n",
    "    articles_id =[]\n",
    "    articles_journal =[]\n",
    "    articles_abstract = []\n",
    "    articles_disease = []\n",
    "    articles_species= []\n",
    "\n",
    "    for i in range (0, len(input_data)):\n",
    "        articles_id.append(input_data[i][\"id\"])\n",
    "        #articles_journal.append (input_data[i][\"journal\"])\n",
    "        articles_abstract.append(input_data[i][\"passages\"][1][\"text\"])\n",
    "        Diseases = []\n",
    "        Species = []\n",
    "        for j in range (0,len(input_data[i][\"passages\"][1][\"annotations\"])):\n",
    "            if input_data[i][\"passages\"][1][\"annotations\"][j][\"infons\"][\"type\"] == \"Disease\":\n",
    "                Diseases.append(input_data[i][\"passages\"][1][\"annotations\"][j][\"text\"])\n",
    "            if input_data[i][\"passages\"][1][\"annotations\"][j][\"infons\"][\"type\"] == \"Species\":\n",
    "                Species.append(input_data[i][\"passages\"][1][\"annotations\"][j][\"text\"])\n",
    "        articles_disease.append(Diseases)\n",
    "        articles_species.append(Species)\n",
    "\n",
    "    df_article[\"id\"] = articles_id\n",
    "    #df_article[\"journal\"] = articles_journal\n",
    "    df_article[\"abstract\"] = articles_abstract\n",
    "    df_article[\"diseases\"] = articles_disease\n",
    "    df_article[\"species\"] = articles_species\n",
    "\n",
    "    return df_article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text, nlp):\n",
    "    # Function to pre-process abstracts\n",
    "    # Normalizamos el texto\n",
    "    norm_text = unidecode(text).lower()\n",
    "    # Eliminamos caracteres especiales\n",
    "    pat = re.compile(r\"[^a-z]\")\n",
    "    clean_text = re.sub(pat, \" \", norm_text)\n",
    "    # Eliminamos espacios duplicados\n",
    "    spaces = re.compile(r\"\\s{2,}\")\n",
    "    spaces_text = re.sub(spaces,\" \", clean_text)\n",
    "    # Extraemos tokens\n",
    "    tokens = list(nlp(spaces_text))\n",
    "    # Filtramos palabras por longitud\n",
    "    filtered_tokens = filter(\n",
    "            lambda token: (\n",
    "                len(token) > 3 and\n",
    "                not token.is_stop  # Filtramos stopwords\n",
    "                ),\n",
    "            tokens\n",
    "        )\n",
    "    filtered_text = \" \".join(token.text for token in filtered_tokens)\n",
    "\n",
    "    return filtered_text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filtering_peptides(df,list_p):\n",
    "    # Function to filter peptides in abstracts\n",
    "    filtered_peptides = []\n",
    "    for i in range (0,len(df[\"abstract\"].to_list())):\n",
    "        text = df[\"abstract\"].to_list()[i]\n",
    "        tokens = list(nlp(text))\n",
    "        filtered_tokens = filter(lambda token: (token.text in list_p), tokens)\n",
    "        filtered_peptides.append(\" \".join(token.text for token in filtered_tokens))\n",
    "    return filtered_peptides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lectura de archivos json y conversión en dataframe\n",
    "data = json_to_list(17900)\n",
    "df_all_articles = extract_jsons_to_df(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pre-process abstracts\n",
    "df_all_articles[\"abstract\"] = df_all_articles[\"abstract\"].apply(lambda x: preprocess(x,nlp))\n",
    "#filtering peptides\n",
    "list_peptides = ['abaecin', 'acaloleptin', 'acanthaporin', 'acanthoscurrin', 'acidocin', 'acipensin', 'actagardine', 'adepantin', 'adrenomedullin', 'afusinc', 'agelaia', 'alamethicin', 'alarin', 'alloferon', 'allomyrinasin', 'alvinellacin', 'alyteserin', 'amoebapore', 'amolopin', 'amurin', 'amylin', 'amylocyclicin', 'andersonin', 'andricin', 'androctonin', 'androctonus', 'andropin', 'anoplin', 'antapin', 'apidaecin', 'arasin', 'arenicin', 'ascaphin', 'astacidin', 'aurein', 'aureocin', 'baceridin', 'bactenecin', 'bactericidin', 'bacteriocin', 'bactofencin', 'bactridine', 'bactrocerin', 'balteatide', 'batroxicidin','bldesin', 'bombinin', 'bombolitin', 'bovine', 'bradykinin', 'brazzein', 'brevifactin', 'brevinin', 'buforin', 'buthinin', 'butyrivibriocin', 'buwchitin', 'caenacin', 'caerin', 'caerulein', 'callinectin', 'capidermicin', 'capistruin', 'carnobacteriocin', 'carnocin', 'carnocyclin', 'casecidin', 'cathelicidin', 'cecropin', 'centrocin', 'ceratotoxin', 'cerecidin', 'chemerin', 'chensinin', 'chromacin', 'chrombacin', 'chrysophsin', 'cinnamycin', 'circularin', 'circulin', 'citrocin', 'citropin', 'clavanin', 'clavaspirin', 'cliotide', 'coleoptericin', 'colistin', 'coprisin', 'copsin', 'corticostatin', 'crabrolin', 'cremycin', 'crinicepsin', 'crotalicidin', 'crotamine', 'cryptdin', 'cryptonin', 'ctenidin', 'ctriporin', 'cupiennin', 'curvacin', 'curvaticin', 'cyanophlyctin', 'cyanovirin', 'cyclopsychotride', 'cyclosaplin', 'cycloviolacin', 'cycloviolin', 'cypemycin', 'cytolysin', 'dahlein', 'datucin', 'defensin', 'delftibactin', 'dendropsophin', 'dermaseptin', 'dermatoxin', 'dermcidin', 'deserticolin', 'desotamide', 'diapausin', 'diptericin', 'distinctin', 'divercin', 'divergicin', 'dolabellanin', 'dominulin', 'dosotamide', 'drosocin', 'drosomycin', 'duramycin', 'durancin', 'dybowskin', 'enbocin', 'enterocin', 'esculentin', 'fabatin', 'feleucin', 'fengycin', 'formaecin', 'formicin', 'frenatin', 'fusaricidin', 'gaegurin', 'gageostatin', 'gageotetrin', 'galensin', 'gallerimycin', 'gallidermin', 'gallin', 'gallinacin', 'gambicin', 'garvicin', 'geobacillin', 'ginkbilobin', 'gramicidin', 'griffithsin', 'griselimycin', 'guentherin', 'hadrurin', 'hainanenin', 'halictine', 'haliotisin', 'halocidin', 'halocin', 'hdmolluscidin', 'heliocin', 'heliomicin', 'hepcidin', 'heterin', 'heteroscorpine', 'hinnavin', 'hipposin', 'hiracin', 'hispidalin', 'holosin', 'holothuroidin', 'holotricin', 'hominicin', 'hymenochirin', 'hymo', 'hyphancin', 'hyposin', 'imcroporin', 'indolicidin', 'isracidin', 'ixodidin', 'ixosin', 'jaburetox', 'japonicin', 'jelleine', 'jindongenin', 'jingdongin', 'kalata', 'kaliocin', 'kassinatuerin', 'kassorin', 'kenojeinin', 'labaditin', 'labyrinthopeptin', 'lacrain', 'lactacin', 'lacticin', 'lactocin', 'lactococcin', 'lactococcin', 'lactocyclicin', 'lactoferricin', 'lactolisterin', 'lariatin', 'lasiocepsin', 'lasioglossin', 'lassomycin', 'laterosporulin', 'laticeptin', 'lebocin', 'leucocin', 'leucrocin', 'lichenicidin', 'lichenin', 'lividin', 'locustin', 'longicin', 'longicornsin', 'longipin', 'lucifensin', 'lucilin', 'lugensin', 'lumbricin', 'lunasin', 'lunatusin', 'lycocitin', 'lycotoxin', 'lynronne', 'lysozyme', 'macropin', 'maculatin', 'maeucath', 'magainin', 'marmelittin', 'mastoparan', 'maximin', 'medusin', 'megin', 'melectin', 'melimine', 'melittin', 'mersacidin', 'mesentericin', 'metalnikowin', 'metchnikowin', 'meucin', 'micasin', 'microbisporicin', 'microcin', 'micrococcin', 'microplusin', 'moronecidin', 'mucroporin', 'mundticin', 'muscin', 'mutacin', 'myticalin', 'mytichitin', 'myticin', 'mytilin', 'mytilus', 'mytimacin', 'myxinidin', 'nabaecin', 'naegleriapore', 'neuromacin', 'neurotensin', 'nicomicin', 'nigroain', 'nigrocin', 'nisin', 'nukacin', 'ocellatin', 'odoranain', 'odorranain', 'omwaprin', 'oncorhyncin', 'opiscorpine', 'opistoporin', 'oreoch', 'ovispirin', 'oxyopinin', 'oxysterlin', 'paenibacillin', 'paenibacterin', 'paenicidin', 'palicourein', 'palustrin', 'pandinin', 'panitide', 'pantocin', 'panurgine', 'panusin', 'papiliocin', 'papilosin', 'parabutoporin', 'paracentrin', 'paralithocin', 'parasin', 'pardaxin', 'parigidin', 'parkerin', 'patellamide', 'pediocin', 'pelophylaxin', 'pelovaterin', 'penaeidin', 'penisin', 'penocin', 'perfrin', 'perinerin', 'persulcatusin', 'phoratoxin', 'phormicin', 'phylloseptin', 'phylloxin', 'piceain', 'pilosulin', 'piscicolin', 'piscidin', 'planosporicin', 'plantaricin', 'plantaricyclin', 'plantazolicin', 'plasticin', 'plectasin', 'pleskein', 'pleurain', 'pleurocidin', 'plicatamide', 'polymyxin', 'ponericin', 'potamin', 'procambarin', 'prolixicin', 'prophenin', 'protegrin', 'protonectin', 'psacotheasin', 'psalmopeotoxin', 'psdefensin', 'pseudhymenochirin', 'pseudin', 'psyle', 'pyrrhocoricin', 'ranacyclin', 'ranalexin', 'ranatuerin', 'raniseptin', 'rattusin', 'regiiialpha', 'retrocyclin', 'rondonin', 'roseocin', 'rugosin', 'ruminococcin', 'sakacin', 'salivaricin', 'salmocidin', 'sapecin', 'sarconesin', 'sarcotoxin', 'scapularisin', 'scarabaecin', 'schmackerin', 'sclerosin', 'scolopendin', 'scolopendrasin', 'scolopin', 'scygonadin', 'secretolytin', 'seminalplasmin', 'senegalin', 'serrulin', 'sesquin', 'shepherin', 'shuchin', 'siamycin', 'signiferin', 'spiderine', 'spiniferin', 'spinigerin', 'staphylococcin', 'stigmurin', 'stomoxyn', 'streptococcin', 'strongylocin', 'styelin', 'sublancin', 'subtilin', 'subtilomycin', 'subtilosin', 'tachycitin', 'tachyplesin', 'tachystatin', 'teixobactin', 'temporin', 'tenecin', 'termicin', 'thermophilin', 'theromacin', 'thrombocidin', 'thuricin', 'tigerinin', 'tolworthcin', 'trichamide', 'tricholongin', 'tridecaptin', 'triintsin', 'tritrpticin', 'turgencin', 'uberolysin', 'ubiquicidin', 'ubonodin', 'uperin', 'urechistachykinin', 'urumin', 'variacin', 'vasostatin', 'vejovine', 'virescein', 'viscotoxin', 'wollamide']\n",
    "filtered_peptides = filtering_peptides(df_all_articles,list_peptides)\n",
    "#Adding a new column named peptide --> list of filtered peptides\n",
    "df_all_articles[\"peptide\"] = filtered_peptides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reducing dataframe with articles with at least one peptide \n",
    "df_all_articles = df_all_articles[~(df_all_articles[\"peptide\"]==\"\")]\n",
    "#converting list of diseases in a joined string\n",
    "df_all_articles['diseases'] = df_all_articles['diseases'].apply(lambda x:\" \".join(x))\n",
    "#converting list of species\n",
    "df_all_articles['species'] = df_all_articles['species'].apply(lambda x:\" \".join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pre-process diseases\n",
    "df_all_articles[\"diseases\"] = df_all_articles[\"diseases\"].apply(lambda x: preprocess(x,nlp))\n",
    "#pre-process species\n",
    "df_all_articles[\"species\"] = df_all_articles[\"species\"].apply(lambda x: preprocess(x,nlp))\n",
    "#eliminate duplicate names of found peptides in an abstract \n",
    "df_all_articles[\"peptide\"] = df_all_articles[\"peptide\"].apply(lambda x: \" \".join(sorted(set(x.split()), key=x.split().index)))\n",
    "#eliminate duplicate names of found diseases in an abstract \n",
    "df_all_articles[\"diseases\"] = df_all_articles[\"diseases\"].apply(lambda x: \" \".join(sorted(set(x.split()), key=x.split().index)))\n",
    "#eliminate duplicate names of found species\n",
    "df_all_articles[\"species\"] = df_all_articles[\"species\"].apply(lambda x: \" \".join(sorted(set(x.split()), key=x.split().index)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_all_articles.head())"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
